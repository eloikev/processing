/* bodyvision
 * This program sends a String of data about
 * faces and hands on the screen.
 */

/* The following Processing libraries are required:
 * Processing.net
 */

//Summons the camera, alongside face and hands.
Camera camera;
Face face;
Hand hand;

//Makes Strings to hold together all data.
final public String[] Default = new String[4];
public String all = "";
public String facing = "";
public String handing = "";

//Makes Strings to capture and store individual data.
public int xFace = 0;
public int yFace = 0;
public int wFace = 0;
public int hFace = 0;
public int areaFace = 0;
public int iterationFace = 0; //The current number face being displayed.
public int countFace = 0; //The total number of faces detected.

public int xHand = 0;
public int yHand = 0;
public int wHand = 0;
public int hHand = 0;
public int areaHand = 0;
public int iterationHand = 0; //The current number hand being displayed.
public int countHand = 0; //The total number of hands detected.

//Determines if the camera is frozen or not, or if it is displayed.
public int blocker = 0;
public int player = 0;

//Imports needed libraries and creates a new Server.
import processing.net.*;
Server myServer;

/* setup()
 * Initializes all aspects of the program.
 */
public void setup() {
  fullScreen();
  //size(720, 450);
  frameRate(30);
  noCursor();

  camera = new Camera(this);
  face = new Face(this);
  hand = new Hand(this);

  myServer = new Server(this, 5204);

  Default[0] = "xFace.yFace.wFace.hFace.areaFace.iterationFace.countFace.xHand.yHand.wHand.hHand.areaHand.iterationHand.countHand";
  Default[1] = "0.1.2.3.4.5.6.7.8.9.10.11.12.13";
  Default[2] = "x.y.w.h.area.iteration.count";
  Default[3] = "0.1.2.3.4.5.6";
  print("\n" + Default[0] + "\n" + Default[1] + "\n\n");
}

/* detection()
 * Gets all data and puts them into Strings.
 */
public void detection() {
  face.detect();
  hand.detect();

  facing = face.getAll();
  handing = hand.getAll();
  all = facing + "." + handing;

  xFace = face.getX();
  yFace = face.getY();
  wFace = face.getW();
  hFace = face.getH();
  areaFace = face.getArea();
  countFace = face.getCount();
  iterationFace = face.getIteration();

  xHand = hand.getX();
  yHand = hand.getY();
  wHand = hand.getW();
  hHand = hand.getH();
  areaHand = hand.getArea();
  countHand = hand.getCount();
  iterationHand = hand.getIteration();
}

/* texting()
 * Displays all data Strings on screen.
 */
public void texting() {
  textSize(20);

  fill(0, 0, 255);
  text("All", 10, 20);

  fill(255, 0, 0);
  text(Default[0], 10, 40);
  text(Default[1], 10, 60);

  fill(0, 255, 0);
  text(all, 10, 80);

  fill(0, 0, 255);
  text("Face", 10, 120);

  fill(255, 0, 0);
  text(Default[2], 10, 140);
  text(Default[3], 10, 160);

  fill(0, 255, 0);
  text(facing, 10, 180);

  fill(0, 0, 255);
  text("Hand", 10, 220);

  fill(255, 0, 0);
  text(Default[2], 10, 240);
  text(Default[3], 10, 260);

  fill(0, 255, 0);
  text(handing, 10, 280);
}

/* mousePressed()
 * Takes a screenshot.
 * Precondition: Input from the mouse.
 */
public void mousePressed() {
  saveFrame("Images/####.png");
}

/* keyPressed()
 * Hides/unhides and/or freezes/unfreezes the camera,
 * or takes a screenshot.
 * Precondition: Input from the keyboard.
 */
public void keyPressed() {
  if (keyCode == ENTER) {
    if (player == 1) {
      player = 0;
    } else {
      player = 1;
    }
    camera.play(player);
  }

  if ((keyCode == DELETE) || (keyCode == BACKSPACE)) {
    if (blocker == 1) {
      blocker = 0;
      player = 0;
      camera.play(player);
    } else {
      blocker = 1;
      player = 1;
      camera.play(player);
    }
  }

  if ((keyCode != ENTER) && (keyCode != DELETE) && (keyCode != BACKSPACE)) {
    saveFrame("Images/####.png");
  }
}

/* draw()
 * Runs all methods and sends data to clients.
 */
public void draw() {
  background(0);
  camera.run(blocker);
  detection();
  texting();

  println(all);
  myServer.write(all);
}










/* The following Processing libraries are required:
 * Video
 */

//Import necessary libraries.
import processing.video.Capture;

/* Camera
 * This class creates and displays a camera.
 */
public class Camera {
  //Gets new camera.
  Capture cam;

  //Initializes and runs the camera.
  Camera (PApplet a) {
    cam = new Capture(a, width, height, "pipeline:autovideosrc");
    cam.start();
  }


  /* run()
   * Displays the camera on screen.
   * Precondition: An integer to determine if the
   * camera should be displayed on screen or not.
   */
  public void run(int x) {
    if (cam.available()) {
      cam.read();
    }

    if (x == 0) {
      image(cam, 0, 0);
    } else {
      background(0);
    }

    if (cam.width == 0) {
      return;
    }
  }

  /* plays()
   * Freezes and unfreezes the camera.
   * Precondition: An integer to determine whether to freeze
   * or unfreeze the camera.
   */
  public void play(int x) {
    if (x == 1) {
      println("\nCAMERA IS FROZEN. PRESS A KEY OR CLICK THE MOUSE TO UNFREEZE.");
      cam.stop();
    } else {
      println("\nCAMERA HAS BEEN UNFROZEN. PRESS A KEY OR CLICK THE MOUSE TO FREEZE.");
      cam.start();
    }
  }
}










/* The following Processing libraries are required:
 * DeepVision
 */

//Import necessary libraries.
import ch.bildspur.vision.*;
import ch.bildspur.vision.result.*;

//Creates new DeepVision network.
DeepVision vision;
ULFGFaceDetectionNetwork network;
ResultList<ObjectDetectionResult> detections;

/* Face
 * This class recognizes any faces in view of the camera
 * and draws a box around them.
 */
public class Face {
  private int x; //X value of face.
  private int y; //Y value of face.
  private int w; //Width of face.
  private int h; //Height of face.
  private int area; //Area of face.
  private int count; //Number of faces on screen.
  private int iteration; //Current face on screen being analyzed.

  Face(PApplet b) {
    //Initializes variables to zero.
    x = 0;
    y = 0;
    w = 0;
    h = 0;
    area = 0;
    count = 0;
    iteration = 0;

    //Establishes DeepVision network.
    vision = new DeepVision(b);
    network = vision.createULFGFaceDetectorRFB320();
    network.setup();
  }

  /* detect()
   * Detects faces on camera and draws a box around them.
   */
  public void detect() {
    //Detects any faces on screen.
    detections = network.run(camera.cam);

    //Establishes the look of the box.
    noFill();
    strokeWeight(2f);
    stroke(255, 0, 0);

    //Creates a box around faces.
    for (ObjectDetectionResult detection : detections) {
      x = width - detection.getX();
      y = detection.getY();
      w = detection.getWidth();
      h = detection.getHeight();
      area = detection.getWidth() * detection.getHeight();
      count = detections.size();

      rect(detection.getX(), detection.getY(), detection.getWidth(), detection.getHeight());
    }

    //Determines which face is being analyzed.
    if (iteration < detections.size()) {
      iteration++;
    } else {
      iteration = 1;
    }

    if (detections.size() == 0) {
      count = 0;
      iteration = 0;
    }
  }

  /* getX()
   * Postcondition: The x value of the face.
   */
  public int getX() {
    return x;
  }

  /* getY()
   * Postcondition: The y value of the face.
   */
  public int getY() {
    return y;
  }

  /* getW()
   * Postcondition: The width of the face.
   */
  public int getW() {
    return w;
  }

  /* getH()
   * Postcondition: The height of the face.
   */
  public int getH() {
    return h;
  }

  /* getArea()
   * Postcondition: The area of the face.
   */
  public int getArea() {
    return area;
  }

  /* getIteration()
   * Postcondition: The current face being analyzed.
   */
  public int getIteration() {
    return iteration;
  }

  /* getCount()
   * Postcondition: The number of faces on screen.
   */
  public int getCount() {
    return count;
  }

  /* getAll()
   * Converts all values into Strings and joins them together,
   * with each value separated by a period.
   * Postcondition: A String of all values.
   */
  public String getAll() {
    String s = "";
    String p = ".";
    s = str(x) + p + str(y) + p + str(w) + p + str(h) + p + str(area) + p + str(iteration) + p + str(count);
    return s;
  }
}










/* The following Processing libraries are required:
 * DeepVision
 */

//Import necessary libraries.
import ch.bildspur.vision.*;
import ch.bildspur.vision.result.*;

//Creates new DeepVision network.
DeepVision Vision;
SSDMobileNetwork Network;
ResultList<ObjectDetectionResult> Detections;

/* Hand
 * This class recognizes any hands in view of the camera
 * and draws a box around them.
 */
public class Hand {
  private int x; //X value of hand.
  private int y; //Y value of hand.
  private int w; //Width of hand.
  private int h; //Height of hand.
  private int area; //Area of hand.
  private int count; //Number of hands on screen.
  private int iteration; //Current hand on screen being analyzed.

  Hand(PApplet c) {
    //Initializes variables to zero.
    x = 0;
    y = 0;
    w = 0;
    h = 0;
    area = 0;
    count = 0;
    iteration = 0;

    //Establishes DeepVision network.
    Vision = new DeepVision(c);
    Network = Vision.createHandDetector();
    Network.setup();
  }

  /* detect()
   * Detects hands on camera and draws a box around them.
   */
  public void detect() {
    //Detects any faces on screen.
    Detections = Network.run(camera.cam);

    //Establishes the look of the box.
    noFill();
    strokeWeight(2f);
    stroke(0, 0, 255);

    //Creates a box around faces.
    for (ObjectDetectionResult Detection : Detections) {
      x = width - Detection.getX();
      y = Detection.getY();
      w = Detection.getWidth();
      h = Detection.getHeight();
      area = Detection.getWidth() * Detection.getHeight();
      count = Detections.size();

      rect(Detection.getX(), Detection.getY(), Detection.getWidth(), Detection.getHeight());
    }

    //Determines which face is being analyzed.
    if (iteration < Detections.size()) {
      iteration++;
    } else {
      iteration = 1;
    }

    if (Detections.size() == 0) {
      count = 0;
      iteration = 0;
    }
  }

  /* getX()
   * Postcondition: The x value of the hand.
   */
  public int getX() {
    return x;
  }

  /* getY()
   * Postcondition: The y value of the hand.
   */
  public int getY() {
    return y;
  }

  /* getW()
   * Postcondition: The width of the hand.
   */
  public int getW() {
    return w;
  }

  /* getH()
   * Postcondition: The height of the hand.
   */
  public int getH() {
    return h;
  }

  /* getArea()
   * Postcondition: The area of the hand.
   */
  public int getArea() {
    return area;
  }

  /* getIteration()
   * Postcondition: The current hand being analyzed.
   */
  public int getIteration() {
    return iteration;
  }

  /* getCount()
   * Postcondition: The number of hands on screen.
   */
  public int getCount() {
    return count;
  }

  /* getAll()
   * Converts all values into Strings and joins them together,
   * with each value separated by a period.
   * Postcondition: A String of all values.
   */
  public String getAll() {
    String s = "";
    String p = ".";
    s = str(x) + p + str(y) + p + str(w) + p + str(h) + p + str(area) + p + str(iteration) + p + str(count);
    return s;
  }
}